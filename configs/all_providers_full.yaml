description: Full TritonBench evaluation across all configured providers/models.

modes:
  - raw
  - agentic

languages:
  - cuda
  - triton

models:
  - provider: gemini
    model: gemini-2.5-pro
  - provider: gemini
    model: gemini-2.5-flash
  - provider: anthropic
    model: claude-sonnet-4-5
  - provider: anthropic
    model: claude-haiku-4-5
  - provider: openai
    model: gpt-5
  - provider: openrouter
    model: z-ai/glm-4.6
  - provider: xai
    model: grok-code-fast-1
  - provider: xai
    model: grok-4-fast-reasoning
  - provider: xai
    model: grok-4-0709
  - provider: groq
    model: moonshotai/kimi-k2-instruct-0905

defaults:
  profile_stages: true
  raw:
    cpu_concurrency: max
    gpu_concurrency: 2
    max_jobs: max

verbose: true
profile_stages: true
fast_p_threshold: null
raw_concurrency: max
raw_gpu_concurrency: 2
raw_max_jobs: max

hardware:
  gpu_architecture: Ampere
  gpu_id: 0

problems:
  levels: [1, 2]
  problem_ids: null
  max_problems: null

agentic:
  max_debug_attempts: 3
  max_optimization_cycles: 2

artifacts:
  json_dir: json
  plots_dir: plots/full

visualization:
  enabled: true
  metrics:
    - compilation_rate
    - correctness_rate
    - fast_1_rate
